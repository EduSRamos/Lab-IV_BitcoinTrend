{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metodologia/planejamento\n",
    "\n",
    "Fonte principal: <a id='main_ref'>*Advances in Financial Machine Learning*</a>\n",
    "\n",
    "Fontes:\n",
    "\n",
    "1. <a id='ref_1'></a>[2010] An Empirical Comparison of Machine Learning Models for Time Series Forecasting\n",
    "2. <a id='ref_2'></a>[2013] Machine Learning Strategies for Time Series Prediction\n",
    "3. <a id='ref_3'></a>[2017] Financial Series Prediction - Comparison Between Precision of Time Series Models and Machine Learning Methods\n",
    "4. [2018] The 10 reasons most machine learning funds fail (bom 'resumo' do livro)\n",
    "5. [2013] [ARCHIVED] State-of-the-art in Stock Prediction Techniques\n",
    "6. <a id='ref_6'></a>[2017] Application of machine learning techniques for stock market prediction -  https://github.com/binweng/ShinyStock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">Etapas</span>\n",
    "1. Data download\n",
    "    - M3 competition dataset\n",
    "    - S&P500\n",
    "    - Nasdaq index\n",
    "    - Dow 30\n",
    "    - Tesla\n",
    "    - Amazon\n",
    "    - Facebook/google (empresas que 'explodiram')\n",
    "    - Apple [ref-6](#ref_6)\n",
    "- Data types [ref-6](#ref_6)\n",
    "    - Data sources of stock market\n",
    "    - Technical indicators\n",
    "    - Economic, internet, and social media\n",
    "- Data exploration\n",
    "- Data preprocessing\n",
    "    - Data cleaning\n",
    "        - Missing values\n",
    "    - Detrending\n",
    "        - Running average?\n",
    "    - Deseasonalization\n",
    "        - Seasonality test: autocorrelation for last 12 (months) [ref_1](#ref_1)\n",
    "            - **Bartlett's formula** / Box & Jenkins\n",
    "            - **Time Series Decomposition** - Referencia: Livro *Forecasting: Methods and Applications*\n",
    "            - 'In this approach a centered moving average is applied, and then a month-by-month average is computed on the smoothed series. This average will then be the seasonal average. We subtract that from the original series to create the deseasonalized series.'\n",
    "    - Differencing\n",
    "        - Partial differencing (de Prado)\n",
    "    - Data transformation\n",
    "        - Log transform\n",
    "        - Taking moving averages [ref-1](#ref_1)\n",
    "    - Data normalization\n",
    "        - Scaling\n",
    "            - Linear scaling [ref-1](#ref_1)\n",
    "        - Minmax normalization\n",
    "        - Standardization: mean=0, variance=1\n",
    "- Parameter determination\n",
    "    - Linear models: AIC, BIC [ref-1](#ref_1)\n",
    "    - ML: k-fold CV [ref-1](#ref_1)\n",
    "- Input variables \n",
    "    - Lagged-val [ref-1](#ref_1)\n",
    "    - Price to Earnings ration (P/E ratio) [ref-6](#ref_6)\n",
    "    - Technical indicators [ref-3](#ref_3)\n",
    "    - Bitcoin's market data\n",
    "    - Wikipedia hits - www.wikipediatrends.com [ref-6](#ref_6)\n",
    "    - Sentiment analysis \n",
    "    - Google news data - Appendix I of [ref-6](#ref_6)\n",
    "- Feature generation\n",
    "    - Appendix II of [ref-6](#ref_6)\n",
    "- Feature selection\n",
    "    - Filter methods [ref-2](#ref_2)\n",
    "        - Preprocessing methods; ignoring the effects of the selected subset on the performance of the learning algorithm.\n",
    "        - PCA (nao e' realmente feature selection, vale destacar)\n",
    "        - Clustering (como usa?)\n",
    "        - Correlation with the output\n",
    "    - Wrapper methods [ref-2](#ref_2)\n",
    "        - Search for a good subset using the learning algorithm itself\n",
    "        - Stepwise methods\n",
    "    - Embedded methods [ref-2](#ref_2)\n",
    "        - Variable selection as part of the learning procedure; method-specific.\n",
    "        - Classification trees\n",
    "        - Random forests\n",
    "        - Regularization\n",
    "    - F-test\n",
    "    - Recursive Feature Elimination [ref-6](#ref_6)\n",
    "        - 'RFE is implemented through backwards selection of predictors based on predictor importance ranking.'\n",
    "        - SVM-RFE algorithm\n",
    "            - `sklearn.feature_selection`\n",
    "- Feature importance [main-ref](#main_ref)\n",
    "- Sampling / Resampling / Train/test set split\n",
    "    - Bootstrap\n",
    "- Training\n",
    "    - Loss function\n",
    "    - Early stopping\n",
    "    - Addressing overfitting/underfitting\n",
    "- Model selection\n",
    "- Forecasting\n",
    "    - One-step-ahead\n",
    "        - Use $n$ previous values to predict next one\n",
    "    - Multi-step-ahead \n",
    "        - Iterated: $t+1$, then $t+2$, ..., $t+h$ [ref-2](#ref_2)\n",
    "            - Iterated with $h$-step training criterion (RNN): adopts one-step-ahead, but adapts the model selection criterion in order to take into account the multi-step-ahead objective\n",
    "        - Direct: Learns independently $h$ models  [ref-2](#ref_2)\n",
    "        - MIMO (multiple inputs, multiple outputs): avoids the simplistic assumption of conditional independence between future values made by the Direct  [ref-2](#ref_2)\n",
    "    - Iterated prediction\n",
    "- Evaluation metrics\n",
    "    - Precision/recall (confusion matrix)\n",
    "    - POSIX\n",
    "    - Metrics from [ref-6](#ref_6)\n",
    "        - Accuracy\n",
    "        - Area under the receiver operating characteristic curve (AUC)\n",
    "        - F-measure\n",
    "        - G-mean\n",
    "        - MCC\n",
    "        - Precision\n",
    "        - Sensitivity\n",
    "        - Specificity\n",
    "- Comparison metric\n",
    "    - MCB [ref_1](#ref_1)\n",
    "    - Giacomini and White [ref_1](#ref_1)\n",
    "    - Frac-best [ref_1](#ref_1)\n",
    "- Validation\n",
    "    - Benchmarks\n",
    "    - Competitions\n",
    "- Backtesting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonte:  *7 reasons most machine learning funds fail*\n",
    "\n",
    "1. Sisyphus paradigm\n",
    "    <br><br>\n",
    "- Integer differentiation\n",
    "    <br><br>\n",
    "- Inefficient sampling\n",
    "    <br><br>\n",
    "- Wrong labeling\n",
    "    <br><br>\n",
    "- Weighting of non-IID samples\n",
    "    <br><br>\n",
    "- Cross-validation leakage\n",
    "    <br><br>\n",
    "- Backtest overfitting\n",
    "    <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Balanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonte: www.google.com\n",
    "\n",
    "1. Item\n",
    "    <br><br>\n",
    "- Item\n",
    "    <br><br>\n",
    "- Item\n",
    "    <br><br>\n",
    "- Item\n",
    "    <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonte: www.google.com\n",
    "\n",
    "1. Item\n",
    "    <br><br>\n",
    "- Item\n",
    "    <br><br>\n",
    "- Item\n",
    "    <br><br>\n",
    "- Item\n",
    "    <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonte: www.google.com\n",
    "\n",
    "1. Item\n",
    "    <br><br>\n",
    "- Item\n",
    "    <br><br>\n",
    "- Item\n",
    "    <br><br>\n",
    "- Item\n",
    "    <br><br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:crypto-env]",
   "language": "python",
   "name": "conda-env-crypto-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
