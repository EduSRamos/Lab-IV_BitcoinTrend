{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referencias:\n",
    "\n",
    "Fontes principais:\n",
    "- <a id='dePrado'><span style='color:red'>dePrado</span></a>: *Advances in Financial Machine Learning*\n",
    "- <a id='AFTS'><span style='color:red'>AFTS</span></a>: *Analysis of Financial Time Series*\n",
    "\n",
    "Livros:\n",
    "- <a id='intro_book'><span style='color:red'>intro_book</span></a>: An Introductory Study on Time-Series Modeling and Forecast\n",
    "- <a id='forecasting'><span style='color:red'>forecasting<span></a>: Forecasting: Methods and Applications (HYNDMAN, Rob)\n",
    "\n",
    "Artigos:\n",
    "- <a id='hetero'><span style='color:red'>hetero</span></a>: [2018] Conditional heteroskedasticity in crypto-assets return\n",
    "- <a id='ref_1'><span style='color:red'>ref_1</span></a></a> An Empirical Comparison of Machine Learning Models for Time Series Forecasting\n",
    "- <a id='ref_2'><span style='color:red'>ref_2</span></a>: [2013] Machine Learning Strategies for Time Series Forecasting\n",
    "- <a id='ref_3'><span style='color:red'>ref_3</span></a>: [2017] Financial Series Prediction - Comparison Between Precision of Time Series Models and Machine Learning Methods\n",
    "- <a id='ref_4'><span style='color:red'>ref_4</span></a>: [2018] The 10 reasons most machine learning funds fail\n",
    "- <a id='ref_6'><span style='color:red'>ref_6</span></a>: [2017] Application of machine learning techniques for stock market prediction\n",
    "- <a id='ref_7'><span style='color:red'>ref_7</span></a>: [2017] Time Series Data Prediction and Analysis\n",
    "- <a id='ref_8'><span style='color:red'>ref_8</span></a>: [2014] Text Mining for Market Prediction - A Systematic Review\n",
    "- <a id='ref_9'><span style='color:red'>ref_9</span></a>: [2006] Effective Feature Preprocessing for Time Series Forecasting\n",
    "- <a id='ref_10'><span style='color:red'>ref_10</span></a>: [2015] Evaluating multiple classifiers for stock price direction prediction\n",
    "- <a id='ref_11'><span style='color:red'>ref_11</span></a>: [2015] Seven sins of quantitative investing\n",
    "- <a id='ref_12'><span style='color:red'>ref_12</span></a>: [1999] Preprocessing Seasonal Time Series for Improving Neural Network Predictions\n",
    "- <a id='ref_13'><span style='color:red'>ref_13</span></a>: [2017] Evaluating Preprocessing Strategies for Time Series Prediction using DL Architectures\n",
    "- <a id='ref_14'><span style='color:red'>ref_14</span></a>: [2010] Feature Selection for Price Change Prediction\n",
    "- <a id='ref_15'><span style='color:red'>ref_15</span></a>: Predicting Stocks with Machine Learning\n",
    "- <a id='ref_17'><span style='color:red'>ref_17</span></a>: On the dangers of cross-validation - an experimental evaluation\n",
    "- <a id='ref_18'><span style='color:red'>ref_18</span></a>: [2009] Stock Price Forecasting by Hybrid Machine Learning Techniques\n",
    "- <a id='ref_19'><span style='color:red'>ref_19</span></a>: [2017] On Feature Reduction using DL for Trend Prediction in Finance\n",
    "- <a id='ref_20'><span style='color:red'>ref_20</span></a>:\n",
    "\n",
    "Outros:\n",
    "- <a id='outro_1'><span style='color:red'>outro_1</span></a>: [2006] Independent comparative study of PCA ICA and LDA on the FERET data set\n",
    "- <a id='outro_2'><span style='color:red'>outro_2</span></a>: [2015] Predicting stock market index using fusion of machine learning techniques\n",
    "\n",
    "Citados:\n",
    "- <a id='cited_1'><span style='color:red'>cited_1</span></a>: [2009] Short-term stock price prediction based on echo state networks\n",
    "- <a id='cited_2'><span style='color:red'>cited_2</span></a>: [2015] High-frequency equity index futures trading using recurrent reinforcement learning with candlesticks.\n",
    "- <a id='cited_3'><span style='color:red'>cited_3</span></a>: [2009] Handling class imbalance in customer churn prediction\n",
    "\n",
    "\n",
    "Links:\n",
    "- <a id='xenon'><span style='color:red'>xenon</span></a>: https://www.xenonstack.com/blog/data-science/time-series-analysis-forecasting-using-machine-learning-deep-learning\n",
    "- <a id='towards'><span style='color:red'>towards</span></a>: https://towardsdatascience.com/time-series-analysis-in-python-an-introduction-70d5a5b1d52a\n",
    "- <a id='vidhya'><span style='color:red'>vidhya</span></a>: https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/\n",
    "- <a id='vidhya2'><span style='color:red'>vidhya2</span></a>: https://www.analyticsvidhya.com/blog/2015/12/complete-tutorial-time-series-modeling/\n",
    "- <a id='duke'><span style='color:red'>duke</span></a>: http://people.duke.edu/~rnau/411home.htm\n",
    "- <a id='auquan'><span style='color:red'>auquan</span></a>: https://medium.com/auquan/tagged/mathematics\n",
    "- <a id='quantinsti'><span style='color:red'>quantinsti</span></a>: https://www.quantinsti.com/blog/forecasting-stock-returns-using-arima-model/\n",
    "- <a id='ethz'><span style='color:red'>ethz</span></a>: http://stat.ethz.ch/~nicolai/timeseries/week2.pdf\n",
    "- <a id='hyndman'><span style='color:red'>hyndman</span></a>: https://robjhyndman.com/talks/RevolutionR/8-Differencing.pdf - **bom resumo pra passar pro povo**\n",
    "- <a id='statsmodel'><span style='color:red'>statsmodel</span></a>: https://www.statsmodels.org/stable/index.html\n",
    "- <a id='stationarity'><span style='color:red'>stationarity</span></a>: https://stats.stackexchange.com/questions/19715/why-does-a-time-series-have-to-be-stationary & https://stats.stackexchange.com/questions/55477/stationarity-requirement-why\n",
    "- <a id='arch'><span style='color:red'>arch</span></a>: http://arch.readthedocs.io/en/latest/univariate/introduction.html\n",
    "- <a id='samir'><span style='color:red'>samir</span></a>: https://ufsj.edu.br/portal2-repositorio/File/martins/cap12_samir.pdf\n",
    "- <a id='harvard'><span style='color:red'>harvard</span></a>: http://iacs-courses.seas.harvard.edu/courses/am207/blog/lecture-17.html - Harvard Lectures in Python\n",
    "- <a id='quantstart'><span style='color:red'>quantstart</span></a>: https://www.quantstart.com/articles/Generalised-Autoregressive-Conditional-Heteroskedasticity-GARCH-p-q-Models-for-Time-Series-Analysis\n",
    "- <a id='arch_effects'><span style='color:red'>arch_effects</span></a>: https://stats.stackexchange.com/questions/77925/procedure-for-fitting-an-arma-garch-model\n",
    "- <a id='r_diagnostics'><span style='color:red'>r_diagnostics</span></a>: https://www.statmethods.net/stats/rdiagnostics.html\n",
    "- <a id='elite'><span style='color:red'>elite</span></a>: https://elitedatascience.com/dimensionality-reduction-algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">Etapas</span>\n",
    "1. Data download\n",
    "    - M3 competition dataset\n",
    "    - S&P500\n",
    "    - Nasdaq index\n",
    "    - Dow 30\n",
    "- **STRUCTURAL BREAK: Cutting the Bitcoin Data when blocks were filled**\n",
    "- Data types [ref-6](#ref_6)\n",
    "    - P/E ratio\n",
    "         - Proxy for fundamental health of company [cited-2](#cited_2)\n",
    "    - Data sources of stock market\n",
    "    - Technical indicators\n",
    "    - Economic, internet, and social media\n",
    "        - Wikipedia hits [ref-6](#ref_6)\n",
    "            - Page views over time\n",
    "            - www.wikipediatrends.com\n",
    "        - Google news Data [ref-6](#ref_6)\n",
    "            - Stock related news daily posted amount\n",
    "            - Count for aggregated news and blogs based on the daily count of content on Google News [ref-6](#ref_6)\n",
    "            \n",
    "    - Sentiment Analysis\n",
    "        - Techniques [ref_8](#ref_8)\n",
    "            - Bag-of-words\n",
    "            - Noun phrases\n",
    "            - Named entities\n",
    "            - Latent Dirichlet Allocation (LDA)\n",
    "        - Dimensionality reduction [ref_8](#ref_8)\n",
    "            - WordNet\n",
    "            - Stemming\n",
    "            - Pre-defined dictionary\n",
    "            - Name-entity recognition\n",
    "        - Feature extraction [ref_8](#ref_8)\n",
    "            - ngrams\n",
    "            - word2vec\n",
    "            - TF-IDF\n",
    "            - TF-CDF\n",
    "        - Feature representation\n",
    "            - Binary\n",
    "            - Float\n",
    "- Data exploration\n",
    "    - Fixed-time data\n",
    "        - Could be better: volume or tick bars - [dePrado](#dePrado)\n",
    "- Data preprocessing\n",
    "    - Data cleaning\n",
    "        - Missing values\n",
    "        - Gaps\n",
    "    - Detrending\n",
    "        - Running average?\n",
    "    - Deseasonalization\n",
    "        - Seasonality test: autocorrelation for last 12 (months) [ref_1](#ref_1)\n",
    "            - **Bartlett's formula** / Box & Jenkins\n",
    "            - **Time Series Decomposition** - Referencia: Livro *Forecasting: Methods and Applications*\n",
    "            - 'In this approach a centered moving average is applied, and then a month-by-month average is computed on the smoothed series. This average will then be the seasonal average. We subtract that from the original series to create the deseasonalized series.'\n",
    "    - Differencing\n",
    "        - Partial differencing (de Prado)\n",
    "        - Alternativas: [ref-8](#ref_8)\n",
    "            - No preprocessing\n",
    "            - Smoothing/moving averages\n",
    "    - Data transformation\n",
    "        - Log transform\n",
    "        - Taking moving averages [ref-1](#ref_1)\n",
    "    - Data normalization\n",
    "        - Scaling\n",
    "            - Linear scaling [ref-1](#ref_1)\n",
    "        - Minmax normalization\n",
    "        - Z-score normalization [ref-A2](#ref_A)\n",
    "        - **Normalize each input of multivariate time series independently** (e.g., open, high, low, etc) [ref-A3](#ref_A)\n",
    "        - Standardization: mean=0, variance=1\n",
    "- Parameter determination\n",
    "    - Linear models: AIC, BIC [ref-1](#ref_1)\n",
    "    - ML: k-fold CV [ref-1](#ref_1)\n",
    "- Input variables \n",
    "    - Lagged-val [ref-1](#ref_1)\n",
    "    - Series of Moving Averages (window=1,2,4,8...) [ref-1](#ref_1)\n",
    "    - Price to Earnings ration (P/E ratio) [ref-6](#ref_6)\n",
    "    - Technical indicators [ref-3](#ref_3)\n",
    "    - Bitcoin's market data\n",
    "    - Wikipedia hits - www.wikipediatrends.com [ref-6](#ref_6)\n",
    "    - Sentiment analysis \n",
    "    - Google news data - Appendix I of [ref-6](#ref_6)\n",
    "- Feature generation\n",
    "    - Appendix II of [ref-6](#ref_6)\n",
    "- Feature extraction\n",
    "    - PCA (nao e' realmente feature selection, vale destacar) [outro-1](#outro_1)\n",
    "        - Lembrar de normalizar os dados\n",
    "        - [cited-1](#cited_1) mostrou que melhora performance\n",
    "        - Kernel PCA\n",
    "    - (Denoising) Auto-Encoder (AE)\n",
    "    - Restricted Boltzmann\n",
    "    - t-SNE (t-distributed Stochastic Neighbor Embedding)\n",
    "    - LDA (Linear discriminant analysis)\n",
    "        - maximizes the separability between classes\n",
    "        - requires labeled data\n",
    "    - ICA (Independent Component Analysis)\n",
    "        - In ICA the basis you want to find is the one in which each vector is an independent component of your data\n",
    "- Feature selection\n",
    "    - **VAMOS FOCAR MAIS EM DIMENSIONALITY REDUCTION E DEIXAR SELECTION SO COM DOIS TIPOS: 'FILTER' E 'EMBEDDED'.\n",
    "        ALEM DISSO, SERA UTILIZADO FEATURE IMPORTANCE**\n",
    "    - Filter methods [ref-2](#ref_2)\n",
    "        - Preprocessing methods; ignoring the effects of the selected subset on the performance of the learning algorithm.\n",
    "        - Clustering (como usa?)\n",
    "        - **Correlation feature-feature and feature-output - threshold** [ref-14](#ref_14)\n",
    "        - **Mutual information (normalized/max)** [ref-14](#ref_14)\n",
    "        - **Variance threshold**\n",
    "    - Wrapper methods [ref-2](#ref_2)\n",
    "        - Search for a good subset using the learning algorithm itself\n",
    "        - Stepwise methods - NOT RECOMMENDED [elite](#elite)\n",
    "            - Recursive Feature Elimination [ref-6](#ref_6)\n",
    "                - 'RFE is implemented through backwards selection of predictors based on predictor importance ranking.'\n",
    "                - SVM-RFE algorithm\n",
    "                    - `sklearn.feature_selection`\n",
    "    - **Embedded methods** [ref-2](#ref_2)\n",
    "        - Variable selection as part of the learning procedure; method-specific.\n",
    "        - Classification trees\n",
    "        - Random forests\n",
    "        - **Regularization**\n",
    "    - F-test\n",
    "- Feature importance [main-ref](#main_ref)\n",
    "- Train/val/test set split\n",
    "    - **Balanced/Imbalanced** data\n",
    "        - Oversampling/undersampling [ref-10](#ref_10) [cited-3](#cited_3)\n",
    "    - Fixed vs Sliding window\n",
    "        - Fixed: trains from A-B and tests from C-D\n",
    "        - Sliding: trains from A-B and tests from B+1-C\n",
    "        - New model for every window\n",
    "    - **Forward chaining**\n",
    "        - fold 1 : training [1], test [2]\n",
    "        - fold 2 : training [1 2], test [3]\n",
    "        - fold 3 : training [1 2 3], test [4]\n",
    "        - fold 4 : training [1 2 3 4], test [5]\n",
    "        - fold 5 : training [1 2 3 4 5], test [6]\n",
    "\n",
    "- Sampling / Resampling\n",
    "    - Bootstrap\n",
    "- Models\n",
    "    - **Logistic Regression** [ref-3](#ref_3) [ref-10](#ref_10)\n",
    "    - **SVM** [ref-3](#ref_3), [ref-6](#ref_6) [ref-10](#ref_10) [outro-2](#outro_2)\n",
    "    - **Random Forest** [ref-10](#ref_10) [outro-2](#outro_2)\n",
    "    - **AdaBoost** [ref-10](#ref_10)\n",
    "    - **LSTM**\n",
    "    - Denoising Auto-encoder (with SVM) [ref-3](#ref_3)\n",
    "- Training\n",
    "    - Loss function\n",
    "        - **Binary cross-entropy**\n",
    "        - **Negative log-likelihood**\n",
    "        - **Soft-margin classifier / Hinge loss**\n",
    "    - Early stopping\n",
    "    - Addressing overfitting/underfitting\n",
    "        - Regularization\n",
    "- Model selection\n",
    "    - Internal (select model given a class, e.g., hyperparameter tuning)\n",
    "        - **(Random) grid search**\n",
    "            - Random for deep learning, specially\n",
    "        - Metrics\n",
    "            - SEE *Evaluation metrics* item\n",
    "    - External (select among classes of models, e.g., SVM, RF, ...)\n",
    "        - SEE *Evaluation metrics* and *Comparison metrics* items\n",
    "- Forecasting\n",
    "    - One-step-ahead\n",
    "        - Use $n$ previous values to predict next one\n",
    "    - Multi-step-ahead \n",
    "        - Iterated: $t+1$, then $t+2$, ..., $t+h$ [ref-2](#ref_2)\n",
    "            - Iterated with $h$-step training criterion (RNN): adopts one-step-ahead, but adapts the model selection criterion in order to take into account the multi-step-ahead objective\n",
    "        - Direct: Learns independently $h$ models  [ref-2](#ref_2)\n",
    "        - MIMO (multiple inputs, multiple outputs): avoids the simplistic assumption of conditional independence between future values made by the Direct  [ref-2](#ref_2)\n",
    "    - Iterated prediction\n",
    "- Feature importance\n",
    "    - Backtesting is **not** research tool [dePrado](#dePrado)\n",
    "- Evaluation metrics\n",
    "    - Different weighting for false positives/negatives\n",
    "    - Metrics from [ref-6](#ref_6)\n",
    "        1. **Confusion Matrix**\n",
    "        - **Accuracy [ref-3](#ref_3) / Precision / Recall(sensitivity) / Specificity**\n",
    "            - **Precision/recall curve**\n",
    "                - Exclusivo para ML; para AR nao faz tanto sentido (o target la e' o valor absoluto, nao 0/1)\n",
    "        - **Area under the receiver operating characteristic curve (AUC-ROC)**\n",
    "            - Exclusivo para ML; para AR nao faz tanto sentido (o target la e' o valor absoluto, nao 0/1)\n",
    "        - **F1-score**\n",
    "        - **Mathews Correlation Coefficient (MCC)**\n",
    "        - POCID\n",
    "- Comparison metric\n",
    "    - MCB [ref_1](#ref_1)\n",
    "    - Giacomini and White [ref_1](#ref_1)\n",
    "    - Frac-best [ref_1](#ref_1)\n",
    "    - Friedman test [ref-10](#ref_10)\n",
    "    - Two Samples Whitney Mann U test [ref-15](#ref_15)\n",
    "    - ANOVA\n",
    "- Validation\n",
    "    - Benchmarks\n",
    "    - Competitions\n",
    "- Backtesting\n",
    "\n",
    "- Pontos positivos\n",
    "    - Learning side and size separately [ref-4](#ref_4)\n",
    "    - Feature importance analysis [ref-4](#ref_4)\n",
    "    - Cross-validation lack of leakage [ref-4](#ref_4)\n",
    "        - Purging and embargoing\n",
    "    - Better bootstrapping [ref-4](#ref_4)\n",
    "        - Uniqueness weighting and sequential bootstrapping [dePrado](#dePrado)\n",
    "    - Backtesting representativeness and avoidance of overfitting\n",
    "        - Combinatorial purged CV [dePrado](#dePrado)\n",
    "    - Data-snooping bias [ref-11](#ref_11)\n",
    "- Expansions\n",
    "    - Outlier handling [ref-11](#ref_11)\n",
    "    - Deseasonalization, detrending, denoising [ref-12](#ref_12)\n",
    "    - Genetic algorithm for feature selection [ref-9](#ref_9)\n",
    "- Shortcomings\n",
    "    - Chronological sampling [ref-4](#ref_4)\n",
    "    - Integer differentiation [ref-4](#ref_4)\n",
    "    - Survivorship bias [ref-11](#ref_11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:purple'>Decided</span>\n",
    "\n",
    "1. Data\n",
    "    - **Time-series**\n",
    "    - **Technical Indicators**\n",
    "- Forecasting\n",
    "    - **One-step ahead**\n",
    "        - Same model\n",
    "            - Predicts for a series of days, starting at a moment $t+d$, in which $d$ is the number of past dependencies.\n",
    "                - This is good for VALIDATION and MODEL SELECTION\n",
    "            - Predicts for next day\n",
    "                - This \n",
    "        - New model\n",
    "    - Week-ahead\n",
    "        - Preve para todos os dias da proxima semana\n",
    "        - Usa o metodo **recursivo** (predicao de hoje e' entrada de amanha)\n",
    "- Evaluation metrics\n",
    "    - Different weighting for false positives/negatives\n",
    "    - Metrics from [ref-6](#ref_6)\n",
    "        1. **Confusion Matrix**\n",
    "        - **Accuracy / Precision / Recall(sensitivity) / Specificity**\n",
    "        - **Area under the receiver operating characteristic curve (AUC-ROC)**\n",
    "        - **F1-score**\n",
    "        - **Mathews Correlation Coefficient (MCC)**\n",
    "        - POCID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonte:  *7 reasons most machine learning funds fail*\n",
    "\n",
    "1. Sisyphus paradigm\n",
    "    <br><br>\n",
    "- Integer differentiation\n",
    "    <br><br>\n",
    "- Inefficient sampling\n",
    "    <br><br>\n",
    "- Wrong labeling\n",
    "    <br><br>\n",
    "- Weighting of non-IID samples\n",
    "    <br><br>\n",
    "- Cross-validation leakage\n",
    "    <br><br>\n",
    "- Backtest overfitting\n",
    "    <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Balanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonte: www.google.com\n",
    "\n",
    "1. Item\n",
    "    <br><br>\n",
    "- Item\n",
    "    <br><br>\n",
    "- Item\n",
    "    <br><br>\n",
    "- Item\n",
    "    <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonte: www.google.com\n",
    "\n",
    "1. Item\n",
    "    <br><br>\n",
    "- Item\n",
    "    <br><br>\n",
    "- Item\n",
    "    <br><br>\n",
    "- Item\n",
    "    <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonte: www.google.com\n",
    "\n",
    "1. Item\n",
    "    <br><br>\n",
    "- Item\n",
    "    <br><br>\n",
    "- Item\n",
    "    <br><br>\n",
    "- Item\n",
    "    <br><br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:crypto-env]",
   "language": "python",
   "name": "conda-env-crypto-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
