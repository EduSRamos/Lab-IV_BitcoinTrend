{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roteiro\n",
    "## Obs.: Fazer um modulo \"Data Analysis/Preparation\" e outro \"Feature Engineering\" antes dos de AR e ML?\n",
    "---\n",
    "Fonte principal: *Analysis of Financial Time Series*\n",
    "\n",
    "Fontes adicionais:\n",
    "1. https://medium.com/auquan/tagged/mathematics\n",
    "\n",
    "## <span style=\"color:red\">Etapas de Analise</span>\n",
    "---\n",
    "\n",
    "Fonte: *Analysis of FTS*\n",
    "\n",
    "1. Estudo da serie temporal em si\n",
    "    - Tipos de retorno (log, etc)\n",
    "        - One period simple return ($R_t$)\n",
    "        - Multiperiod simple return\n",
    "        - Log return ($r_t$)\n",
    "    - Estacionariedade\n",
    "        - Complex roots of (characteristic equation?) lie outside (inside?) the unit circle\n",
    "    - Correlation and autocorrelation functions (2.2)\n",
    "        - ACF\n",
    "        - Testing Individual ACF\n",
    "        - **Portmanteau Test** \n",
    "            - **Ljung-Box modification**\n",
    "     <br><br>\n",
    "2. AR models (2.4)\n",
    "    - Stationarity condition (2.4.1 - ex. 2.1)\n",
    "    - Identifying AR models in practice (2.4.2)\n",
    "        - PACF and AIC/BIC\n",
    "        - Model selection\n",
    "        - Parameter estimation\n",
    "        - Model checking\n",
    "            - ACF\n",
    "            - Ljung-Box statistics\n",
    "    - Goodness of Fit\n",
    "        - Adjusted-$R^2$\n",
    "    - Forecasting \n",
    "        - 1-step ahead\n",
    "        - Multistep ahead\n",
    "    <br><br>\n",
    "3. MA models\n",
    "    - Identifying MA order\n",
    "        - ACF\n",
    "    - Estimation of parameters\n",
    "        - MLE\n",
    "     <br><br>\n",
    "- ARMA models (2.6)\n",
    "    - Model\n",
    "    - Properties (expected value and variance)\n",
    "    - Identifying ARMA models (2.6.3)\n",
    "        - EACF\n",
    "        - AIC/BIC\n",
    "     <br><br>\n",
    "- ARIMA - Unit-Root Nonstationarity\n",
    "    - Unit-root test\n",
    "        - Dickey-Fuller test\n",
    "    - Augmented Dickey-Fuller\n",
    "    - Ver Ex. 2.2\n",
    "     <br><br>\n",
    "- Seasonal Models?\n",
    "    - Seasonal differencing\n",
    "     <br><br>\n",
    "- (G)ARCH (ch3)\n",
    "    - Model Building (3.3)\n",
    "        - Testing for ARCH effects\n",
    "            - **Ljung-Box statistics**\n",
    "            - **Lagrange Multiplier Test of Engle**\n",
    "    \n",
    "---\n",
    "Fonte: https://www.quantinsti.com/blog/forecasting-stock-returns-using-arima-model/\n",
    "\n",
    "1. Testing and ensuring stationarity\n",
    "    - Augmented Dickey-Fuller\n",
    "        - Differencing (if non-stationary)\n",
    "    <br><br>\n",
    "2. Identification of `p` and `q`\n",
    "    - `p`: ACF/PACF\n",
    "    - `q`: ACF (acho que esta em desacordo com o livro)\n",
    "    <br><br>\n",
    "3. Estimation and forecast\n",
    "    \n",
    "Implementacao em R:\n",
    "1. Pull stock data\n",
    "2. *Compute logarithmic returns*\n",
    "3. ADF\n",
    "4. *Split training / testing*\n",
    "5. Estimation\n",
    "6. *Model Accuracy*\n",
    "    - AIC\n",
    "---\n",
    "Fonte: https://www.xenonstack.com/blog/data-science/time-series-analysis-forecasting-using-machine-learning-deep-learning\n",
    "\n",
    "1. Time Series Forecasting Methods\n",
    "    - Univariate vs Multivariate\n",
    "2. Time Series Forecasting Models\n",
    "    - ARIMA\n",
    "        - Each part of 'ARIMA' name\n",
    "    - ARCH/GARCH\n",
    "    - ~~VAR~~\n",
    "    - LSTM\n",
    "    - ELMAN and JORDAN neural networks\n",
    "3. Approaches to Time Series Analysis\n",
    "    - Univariate\n",
    "        - How to determine if time series is stationary\n",
    "            - Rolling mean, Dickey-Fuller, differencing\n",
    "        - ARIMA\n",
    "    - Multivariate\n",
    "4. Other topics\n",
    "---\n",
    "Fonte: https://towardsdatascience.com/time-series-analysis-in-python-an-introduction-70d5a5b1d52a\n",
    "\n",
    "1. Intro\n",
    "    - Additive model: represent a time series as a combination of patterns at different scales\n",
    "    <br><br>\n",
    "2. Using Quandl to retrieve stock data\n",
    "    <br><br>\n",
    "- Data Exploration\n",
    "    - Market cap\n",
    "    <br><br>\n",
    "- Modeling with **Prophet**\n",
    "    > Bem bacana, vale a pena brincar\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonte: https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/\n",
    "\n",
    "(Bastante **codigo que da pra aproveitar**)\n",
    "\n",
    "1. What makes time series special?\n",
    "    - Time dependent / seasonality trends\n",
    "- Loading and handling data in Pandas\n",
    "- How to check stationarity of time series?\n",
    "    - Stationary\n",
    "        - Constant mean, constant variance, autocovariance independent in time\n",
    "    - Test - ver **codigos**\n",
    "        - Rolling statistics (average/variance) - visual technique\n",
    "        - Dickey-Fuller\n",
    "    <br><br>\n",
    "- How to make a time series stationary?\n",
    "    - Reasons for non-stationarity\n",
    "        - Trend\n",
    "        - Seasonality\n",
    "    - Log transform\n",
    "    - Estimate or model trend\n",
    "        - Aggregation: average for a period of like weekly/monthly averages\n",
    "        - Smoothing: moving averages\n",
    "        - Polynomial Fitting: regression model\n",
    "    - Smoothing: ver codigo\n",
    "        - Funcao `test_stationarity`\n",
    "    - Eliminating trend and seasonality\n",
    "        - Differencing \n",
    "        - Decomposition\n",
    "            - `from statsmodels.tsa.seasonal import seasonal_decompose`\n",
    "            - Stationarity of residuals\n",
    "    <br><br>\n",
    "- Forecasting a time series (bons **codigos**)\n",
    "    - ARIMA\n",
    "        - Parameters `(p,d,q)`: ACF and PACF\n",
    "    - AR\n",
    "    - MA\n",
    "    - Taking it back to the original scale\n",
    "    <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonte: https://medium.com/auquan/tagged/mathematics\n",
    "\n",
    "1. Stationarity, Autocorrelation and White Noise\n",
    "    - Why do we care about stationarity?\n",
    "        - A stationary time series (TS) is simple to predict as we can assume that future statistical properties are the same or proportional to current statistical properties. Most of the models we use in TSA assume covariance-stationarity (#3 above). This means the predictions of these models - means, variances, and correlations, are only reliable if the TS is stationary and invalid otherwise.\n",
    "    - Autocorrelation\n",
    "        - Time series has 3 components: trend, seasonal and random\n",
    "    - White noise\n",
    "    - Random walk\n",
    "    <br><br>\n",
    "- AR Models\n",
    "    - Ver funcao `tsplot` (no artigo tem codigo)\n",
    "    - 'Data fitting' e' uma parte boa\n",
    "    - 'Note on choosing number of lags'\n",
    "        - ACF/PACF and AIC\n",
    "    - 'Evaluating residuals'\n",
    "        - Our goal is to find a model to fit our series so that the residuals are white noise\n",
    "        - `jarque_bera` function from `statsmodels` package\n",
    "    - Application to financial series \n",
    "        - Interessante; avalia os residuos e ve que AR e' insuficiente\n",
    "    <br><br>\n",
    "- MA Models\n",
    "    <br><br>\n",
    "- ARMA Models\n",
    "    <br><br>\n",
    "- ARIMA Models\n",
    "    - Regime Detection\n",
    "    <br><br>\n",
    "- GARCH Model\n",
    "    - 'What is Conditional Heteroskedasticity?'\n",
    "    - 'Application to Financial Time Series' e' bacana, mostra um passo-a-passo\n",
    "    - 'Strategy results' e' legal tb\n",
    "    <br><br>\n",
    "    \n",
    "- Obs.: Parece que tem funcoes pra simular AR, MA, ARMA, ARIMA processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonte: https://www.analyticsvidhya.com/blog/2015/12/complete-tutorial-time-series-modeling/\n",
    "\n",
    "1. Basics\n",
    "    - Stationarity\n",
    "    - Dickey-Fuller Test\n",
    "    <br><br>\n",
    "- Exploration of Time Series Data in R\n",
    "    <br><br>\n",
    "- ARMA\n",
    "    - AR or MA are not applicable on non-stationary series\n",
    "    - AR and MA\n",
    "        - 'Did you notice the difference between MA and AR model? In MA model, noise / shock quickly vanishes with time. The AR model has a much lasting effect of the shock.'\n",
    "    - ACF and PACF plots\n",
    "        - 'In a moving average series of lag n, we will not get any correlation between x(t) and x(t â€“ n -1) . Hence, the total correlation chart cuts off at nth lag. For an AR series this correlation will gradually go down without any cut off value. So what do we do if it is an AR series?'\n",
    "        - 'Here is the second trick. If we find out the partial correlation of each lag, it will cut off after the degree of AR series.'\n",
    "    <br><br>\n",
    "- Framework and Application of ARIMA Time Series Modeling\n",
    "    1. Visualize the time series\n",
    "    - Stationarize\n",
    "        - Detrending\n",
    "        - Differencing\n",
    "        - Seasonality\n",
    "    - Find optimal parameters (ACF/PACF)\n",
    "        - 'if both ACF and PACF decreases gradually, it indicates that we need to make the time series stationary and introduce a value to \"d\"'\n",
    "    - Build the ARIMA model\n",
    "    - Make Predictions\n",
    "    <br><br>\n",
    "- Example\n",
    "    - 'ACF plot cuts off after the first lag. Hence, we understood that value of p should be 0 as the ACF is the curve getting a cut off. While value of q should be 1 or 2. After a few iterations, we found that (0,1,1) as (p,d,q) comes out to be the combination with least AIC and BIC.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonte: *An Introductory Study on Time-Series Modeling and Forecast*\n",
    "\n",
    "1. Intro\n",
    "    - ARIMA\n",
    "    - SARIMA\n",
    "    - ANN and SVM\n",
    "    <br><br>\n",
    "- Basic Concepts\n",
    "    - Definition of a TS\n",
    "    - Components of a TS\n",
    "    <br><br>\n",
    "- Time Series Forecasting using Statistical Models\n",
    "    - SARIMA (3.6)\n",
    "    - Box-Jenkins Methodology (Model selection): 3 step iterative approach\n",
    "        - model identification\n",
    "        - parameter estimation\n",
    "        - diagnostic checking\n",
    "    <br><br>\n",
    "- ANN\n",
    "    <br><br>\n",
    "- SVM\n",
    "    - Empirical risk minimization\n",
    "    - VC dimension\n",
    "    - Structural risk minimization\n",
    "    - Types of SVM\n",
    "        - LS-SVM\n",
    "        - DLS-SVM\n",
    "    <br><br>\n",
    "- Forecast Performance Measures\n",
    "    - Train/valid/test sets\n",
    "    - **Box-cox Transformation**\n",
    "    - Um tanto de metricas\n",
    "    <br><br>\n",
    "- Experimental Results\n",
    "    - Marromenos\n",
    "    <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fontes diversas (tudo que for referenciado por [1], [8], [16], etc, sao artigos na pasta de Lab.IV):\n",
    "- *Forecasting: Methods and Applications (HYNDMAN, Rob)*\n",
    "- *Conditional heteroskedasticity in crypto-assets return*\n",
    "\n",
    "Topicos:\n",
    "1. Data Analysis\n",
    "    - Graphical summaries\n",
    "        - Time plots and time-series patterns\n",
    "        - Seasonal plots\n",
    "        - Scatterplots\n",
    "        - Rolling means and rolling variances give a hint of whether the TS is stationary\n",
    "    - Numerical summaries\n",
    "        - Univariate/bivariate statistics\n",
    "        - Autocorrelation\n",
    "    - Outlier detection ? (SEE [7])\n",
    "        - **Hampel Filter**\n",
    "    - Decomposition (SEE [7])\n",
    "        - Components\n",
    "            - Trend\n",
    "            - Seasonality\n",
    "            - Irregular/random\n",
    "        - Models\n",
    "            - Additive\n",
    "            - Multiplicative\n",
    "            - The growths of the trend or seasonal components may be expressed in percentages (multiplicative) or absolute values (additive)\n",
    "    - ACF and PACF\n",
    "    - **The Box-Jenkins Methodology for ARIMA models** (SEE HYNDMAN, 7)\n",
    "        - Examining correlations in time series data\n",
    "            - **Portmanteau tests**\n",
    "            - PACF\n",
    "            - Recognizing seasonality\n",
    "        - Examining stationarity of time series\n",
    "            - Removing non-stationarity\n",
    "            - Random walk model\n",
    "            - Tests for stationarity\n",
    "                - Rolling means and rolling variances give a hint of whether the TS is stationary\n",
    "                - PACF and ACF \n",
    "                    - For stationary time series, ACF drops drops quickly (otherwise, it drops slowly)\n",
    "                - ADF - Augmented Dickey-Fuller\n",
    "            - **Seasonal differencing**\n",
    "                - ACF helps see the seasonality\n",
    "                - 'Non-seasonal differencing first; then, one seasonal differencing with *lag* ...' (SEE [7], 4.2)\n",
    "            - **Backshift notion**\n",
    "    - Transformations and adjustments\n",
    "        - Denoising\n",
    "            - Smoothing\n",
    "                - Performs some kind of local averaging (SEE [7])\n",
    "                    - Moving average filter\n",
    "                    - Median filter\n",
    "                    - Local regression filter\n",
    "                - Local regression smoothing\n",
    "                - Exponential smoothing\n",
    "                    - Single exponential smooothing\n",
    "                    - Hot's linear method\n",
    "                    - **Holt-Winters** trend and seasonality method (SEE HYNDMAN)\n",
    "        - Differencing\n",
    "            - May be performed multiple times\n",
    "            - Simple($x(t)-x(t-1)$) vs relative($(x(t)-x(t-1))/x(t-1)$)\n",
    "            - *Logarithmic return rate*\n",
    "        - Scaling\n",
    "            - scaling range (-1,1) or (0,1)\n",
    "        - Normalization\n",
    "- Selecting variables (SEE HYNDMAN, 6.2)\n",
    "    - Explanatory variables (SEE HYNDMAN, 6.2.2)\n",
    "    - **Best subset regression**\n",
    "    - Stepwise regression\n",
    "    - **Multicollinearity** - Aproveitar e ver *HASTIE, TIBSHIRANI*\n",
    "    - Economic Models - (SEE HYNDMAN, 6.6)\n",
    "- Forecast Methods\n",
    "    - Forecasting methods vs forecasting models (SEE [7])\n",
    "        - Methods: steps to get a model; includes quality assessment measures\n",
    "        - Model: functional representation that adequately describes a time series\n",
    "    - Two main ways (SEE [7])\n",
    "        - Based only on past values of that specific time series\n",
    "            - Use $k$ previous values to predict the $l$ next ones\n",
    "        - Past values of the same ts + external factors\n",
    "    - Regression methods (SEE HYNDMAN)\n",
    "        - Simple regression and the correlation coefficients\n",
    "        - Cautions in using correlation \n",
    "        - **Residuals, outliers and influential observations**\n",
    "        - **F-test** for overall significance\n",
    "        - **t-tests** for individual coefficients\n",
    "    - Multiple regression (SEE HYNDMAN)\n",
    "        - Checking independence of residuals\n",
    "    - **The Box-Jenkins Methodology for ARIMA models** (SEE HYNDMAN, 7)\n",
    "        - ARIMA models for time series data\n",
    "            - AR, ARMA, ARIMA\n",
    "        - Identification\n",
    "            - SEE examples\n",
    "        - Estimating the parameters\n",
    "        - Forecasting with ARIMA\n",
    "            - Out-of-sample forecasts\n",
    "            - The effect of differencing on forecasts\n",
    "        - Diagnostic Checking (SEE HYNDMAN 7.7)\n",
    "- Goodness of Fit\n",
    "    - **Kolmogorov-Smirnov** and **Cramer von-Mises** criteria (SEE *conditional heteroskedasticity...*)\n",
    "- Residual analysis\n",
    "    - Checking for independence\n",
    "- Measuring forecast accuracy\n",
    "    - Standard statistical methods\n",
    "    - Out-of-sample measure\n",
    "    - Comparing forecasting methods\n",
    "    - **Theil's U-statistic**\n",
    "    - ACF of forecast error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">Ordem de Implementacao</span>\n",
    "\n",
    "1. Copiar notebooks (ou utilizar exemplos) de https://medium.com/auquan/tagged/mathematics, pois eles usam dados sinteticos\n",
    "- Utilizar dados nao-financeiros?\n",
    "- Aplicar a dados do mercado financeiro (fazer uma rotina que pegue os dados)\n",
    "    - Nao 'acoplar' toda a analise ainda\n",
    "- Utilizar algum dado do mercado financeiro e fazer uma analise completa (tentar os modelos, rodar os testes, etc)\n",
    "    - Validar com outros dados\n",
    "- Iterar com dados de diversas firmas ate estar com 'tudo' implementado\n",
    "- EXTRA: brincar com o `Prophet`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
