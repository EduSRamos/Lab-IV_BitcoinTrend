{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coisas temporariamente descartadas de AR_Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.* Testa modelo para estacionariedade e unit-root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(ts, window=30, lags=30):\n",
    "    # Rolling statistics\n",
    "    rolling_stats = roll_stats(ts=ts, window=window)\n",
    "    plotscatter(rolling_stats, title='Rolling Statistics')\n",
    "\n",
    "    # Stationarity test\n",
    "    test_stationarity_kpss(ts['Value'])\n",
    "\n",
    "    # Unit-root test\n",
    "    test_unitroot_adf(ts['Value'])\n",
    "    test_unitroot_phillips_perron(ts['Value'])\n",
    "\n",
    "    # Plot ACF, PACF & QQ\n",
    "    tsplot(ts['Value'], lags=lags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Functions V - Being-validated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "553"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def outliers_modified_z_score(ys):\n",
    "    '''Modified Z score for outliers'''\n",
    "    threshold = 3.5\n",
    "\n",
    "    median_y = np.median(ys)\n",
    "    median_absolute_deviation_y = np.median([np.abs(y - median_y) for y in ys])\n",
    "    modified_z_scores = [0.6745 * (y - median_y) / median_absolute_deviation_y\n",
    "                         for y in ys]\n",
    "    return np.where(np.abs(modified_z_scores) > threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "996"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def outliers_iqr(ys):\n",
    "    '''Outlier Interquartile Range'''\n",
    "    quartile_1, quartile_3 = np.percentile(ys, [25, 75])\n",
    "    iqr = quartile_3 - quartile_1\n",
    "    lower_bound = quartile_1 - (iqr * 1.5)\n",
    "    upper_bound = quartile_3 + (iqr * 1.5)\n",
    "    return np.where((ys > upper_bound) | (ys < lower_bound))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Functions VI - Unused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_mean(ts, columns=None):\n",
    "    '''Subtract the mean of one or more time series.'''\n",
    "    if columns is None: columns = list(ts.columns)\n",
    "    \n",
    "    for col in columns:\n",
    "        mu = ts[col].mean()\n",
    "        ts[col] = ts[col] - mu\n",
    "        \n",
    "    return ts, mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model_order(ts, p_rng, q_rng):\n",
    "    '''Selects ARMA parameters that best \n",
    "        \n",
    "       Input:\n",
    "       - ts: a time series\n",
    "       - p_rng: values to be tested as number of AR terms\n",
    "       - q_rng: values to be tested as number of MA terms \n",
    "       \n",
    "       Outputs\n",
    "       - AIC: a matrix whose entries (i,j) are the Akaike Information Criterion values for a model ARMA(i,j)\n",
    "    '''\n",
    "    ts = ts.dropna(axis=0,how='any')\n",
    "    best_aic = np.inf \n",
    "    best_order = None\n",
    "    \n",
    "    # Some models raise an exception of dividing by NaN or 0\n",
    "    np.seterr(divide='print', invalid='print')\n",
    "\n",
    "    AIC = np.full(shape=(max(p_rng)+1,max(q_rng)+1), fill_value=np.nan)\n",
    "    for i in p_rng:\n",
    "        for j in q_rng:\n",
    "            print(i,j, end=' / ')\n",
    "            if i is 0 and j is 0: continue\n",
    "            try:\n",
    "                tmp_mdl = sm.tsa.ARIMA(ts, order=(i,j)).fit(method='mle', trend='n', maxiter=300)\n",
    "                tmp_aic = tmp_mdl.aic\n",
    "                AIC[i,j] = tmp_aic\n",
    "                if tmp_aic < best_aic:\n",
    "                    best_aic = tmp_aic\n",
    "                    best_order = (i, 0, j)\n",
    "            except: continue\n",
    "    print('AIC: {:.2f} | order: {}'.format(best_aic, best_order))                    \n",
    "    return AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_arima_garch_series(n=1000, p=0, d=0, q=0, m=0, s=0, phi=None,theta=None, alpha=None,beta=None, seed=None):\n",
    "    '''Generate a time series with ARIMA and GARCH effects.'''\n",
    "    # Define seed\n",
    "    if seed is not None: np.random.seed(seed)\n",
    "        \n",
    "    # Coeficientes da parte AR\n",
    "    if phi is None:\n",
    "        char_roots = np.array([10])\n",
    "        while any(char_roots > 1): # Condicao de estacionariedade (se nao for respeitada, diverge a serie)\n",
    "            phi = np.random.rand(p+1)*2 - 1 # inclui phi_0 (constante)\n",
    "            char_roots = np.abs(1 / np.roots(np.r_[np.flip(-phi[1:],axis=-1),[1]]))\n",
    "    \n",
    "    # Coeficientes da parte MA\n",
    "    if theta is None:\n",
    "        theta_roots = np.array([0])\n",
    "        while any(theta_roots < 1):\n",
    "            theta = np.r_[[1],(np.random.rand(q)*2 - 1)] # inclui theta_0 = 1\n",
    "            tmp_theta = -np.flip(theta, axis=-1)\n",
    "            tmp_theta[-1] = 1  # ajusta elemento \n",
    "            theta_roots = np.abs(np.roots(tmp_theta))\n",
    "        \n",
    "    # Ruido branco\n",
    "    if m>0 or s>0:\n",
    "        a, alpha, beta = generate_garch_process(n=n, m=m, s=s, alpha=alpha, beta=beta) # GARCH process residuals\n",
    "    else:\n",
    "        a = np.random.randn(n) # white noise residuals\n",
    "\n",
    "    # Calcula partes referentes ao MA\n",
    "    r_ma = np.convolve(a, theta, 'full') \n",
    "    if q>0: r_ma = r_ma[:-q]\n",
    "    \n",
    "    # Calcula parte referente ao AR e soma com a parte do MA\n",
    "    r = np.ones(n)\n",
    "    for i in np.arange(n):\n",
    "        past_values = r[max(0,i-p):i+1]\n",
    "        coeff = phi[0:min(i+1,p+1)]\n",
    "        r[i] = np.convolve(past_values, coeff, 'valid') + r_ma[i] # adds shock\n",
    "    \n",
    "    # Realiza d integracoes ('I' do 'ARIMA')\n",
    "    for i in range(d):\n",
    "        r = r.cumsum()\n",
    "    \n",
    "    return_dict = {'r':r, 'phi':phi, 'theta':theta, 'a':a, 'alpha':alpha, 'beta':beta}\n",
    "    \n",
    "    return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_garch_process(n=1000, m=1, s=1, alpha=None, beta=None, seed=None):\n",
    "    '''Generate a GARCH process.'''\n",
    "    # Define seed\n",
    "    if seed is not None: np.random.seed(seed)\n",
    "        \n",
    "    # Coeficientes da parte AR *do GARCH*\n",
    "    if alpha is None:\n",
    "        alpha = np.random.rand(m+1) # constante (alpha_0) + coeficientes alpha_i de a_{t-i}, i=1,...,m\n",
    "        \n",
    "    # Coeficientes da parte MA *do GARCH*\n",
    "    if beta is None:\n",
    "        beta = np.random.rand(s)    # coeficientes beta_j de sigma2_{t-j}, j=1,...,s\n",
    "        \n",
    "    # Condicao de validade:\n",
    "    if alpha[0] > 1: alpha[0] = np.random.rand()\n",
    "    for i in range(max(m,s)):\n",
    "        c1 = c2 = 0\n",
    "        if i<m: c1 = alpha[i+1] # se ainda houver coeficiente alpha\n",
    "        if i<s: c2 = beta[i]    # se ainda houver coeficiente beta\n",
    "        if c1+c2 >= 1:\n",
    "            delta = np.random.rand()*0.2\n",
    "            c1 = c1/(c1+c2) - delta\n",
    "            c2 = c2/(c1+c2) - delta\n",
    "        if i<m: alpha[i+1] = c1 # se ainda houver coeficiente alpha\n",
    "        if i<s: beta[i] = c2    # se ainda houver coeficiente beta\n",
    "        \n",
    "    # Ruido branco\n",
    "    eps = np.random.randn(n)\n",
    "        \n",
    "    # Shocks \n",
    "    a = np.ones(n) # importante ser inicializado como 1\n",
    "    sigma2 = np.ones(n)\n",
    "    for t in np.arange(n):\n",
    "        coef_shocks = alpha[0:min(t+1,m+1)]                   # [alpha_0, alpha_1, alpha_2, ...]\n",
    "        past_shocks = np.flip(a[max(0,t-m):t+1], axis=-1)     # flip([..., a_{t-2}, a_{t-1}, 1])\n",
    "        coef_sigmas = beta[0:min(t,s)]                        # [beta_1, beta_2, ...]\n",
    "        past_sigmas = np.flip(sigma2[max(0,t-s):t], axis=-1)  # flip([..., sigma_{t-2}, sigma_{t-1}])\n",
    "        \n",
    "        # Sigma^2_t\n",
    "        sigma2[t] = np.sqrt(np.inner(coef_shocks,past_shocks**2) + np.inner(coef_sigmas,past_sigmas**2))\n",
    "        \n",
    "        # a_t\n",
    "        a[t] = sigma2[t] * eps[t] # multiplica pelo ruido\n",
    "        \n",
    "    return a, alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(ts_true, ts_pred):\n",
    "    df = pd.DataFrame(data={'Real': ts_true, 'Pred': ts_pred})\n",
    "    df = df.dropna(how='any', axis=0)\n",
    "\n",
    "    conf_dict = {'TP': np.sum(df['Pred'][df['Real'] ==  1] ==  1), \n",
    "                 'TN': np.sum(df['Pred'][df['Real'] == -1] == -1), \n",
    "                 'FP': np.sum(df['Pred'][df['Real'] == -1] ==  1), \n",
    "                 'FN': np.sum(df['Pred'][df['Real'] ==  1] == -1)\n",
    "                }\n",
    "\n",
    "    print('{:20s}{:20s}{:20s}'.format('','Real Positive', 'Real Negative'))\n",
    "    print('{:20s}{:10d}{:20d}'.format('Predicted Positive',conf_dict['TP'], conf_dict['FP']))\n",
    "    print('{:20s}{:10d}{:20d}'.format('Predicted Negative',conf_dict['FN'], conf_dict['TN']))\n",
    "    return conf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_metrics(conf_dict):\n",
    "    TP, TN, FP, FN = conf_dict['TP'], conf_dict['TN'], conf_dict['FP'], conf_dict['FN'] \n",
    "    metrics = {'Accuracy':    float((TP + TN)/(TP + TN + FP + FN)),\n",
    "               'Precision':   float((TP)/(TP + FP)),\n",
    "               'Recall':      float((TP)/(TP + FN)), # similar to sensitivity\n",
    "               'Specificity': float((TN)/(TN + FP)),\n",
    "               'Sensitivity': float((TP)/(TP + FN)) # similar to recall\n",
    "              }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:crypto-env]",
   "language": "python",
   "name": "conda-env-crypto-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
